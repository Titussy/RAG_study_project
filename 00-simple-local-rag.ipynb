{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c524a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.8.3 charset_normalizer-3.4.3 idna-3.10 requests-2.32.5 urllib3-2.5.0\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.2-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from sentence_transformers) (2.3.1+cu121)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached scikit_learn-1.7.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Using cached scipy-1.16.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from sentence_transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from sentence_transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached regex-2025.7.34-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n",
      "Requirement already satisfied: sympy in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence_transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence_transformers) (2021.11.0)\n",
      "Requirement already satisfied: colorama in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.8.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Using cached transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached regex-2025.7.34-cp311-cp311-win_amd64.whl (276 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached scikit_learn-1.7.1-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.1-cp311-cp311-win_amd64.whl (38.6 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, safetensors, regex, pyyaml, joblib, scikit-learn, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   --- ------------------------------------  1/11 [scipy]\n",
      "   ------- --------------------------------  2/11 [safetensors]\n",
      "   -------------- -------------------------  4/11 [pyyaml]\n",
      "   -------------- -------------------------  4/11 [pyyaml]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   ------------------ ---------------------  5/11 [joblib]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   --------------------- ------------------  6/11 [scikit-learn]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [tokenizers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence_transformers]\n",
      "   ---------------------------------------- 11/11 [sentence_transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.34.4 joblib-1.5.2 pyyaml-6.0.2 regex-2025.7.34 safetensors-0.6.2 scikit-learn-1.7.1 scipy-1.16.1 sentence_transformers-5.1.0 threadpoolctl-3.6.0 tokenizers-0.21.4 transformers-4.55.4\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch==2.3.1+cu121 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (0.18.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121) (2021.11.0)\n",
      "Requirement already satisfied: numpy in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from jinja2->torch==2.3.1+cu121) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from sympy->torch==2.3.1+cu121) (1.3.0)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.5-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp311-cp311-win_amd64.whl.metadata (111 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.5-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 11.6 MB/s  0:00:00\n",
      "Using cached kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/6 [pyparsing]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   -------------------------- ------------- 4/6 [contourpy]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   ---------------------------------------- 6/6 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.10.5 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests\n",
    "!pip3 install tqdm\n",
    "!pip3 install pandas\n",
    "!pip3 install sentence_transformers\n",
    "!pip3 install torch==2.3.1+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1fe84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23.5 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9070b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.3.1+cu121\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp311-cp311-win_amd64.whl (2423.5 MB)\n",
      "Requirement already satisfied: torchvision in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (0.19.0+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torch==2.3.1+cu121) (2024.6.1)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch==2.3.1+cu121)\n",
      "  Using cached https://download.pytorch.org/whl/mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121)\n",
      "  Using cached https://download.pytorch.org/whl/intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121)\n",
      "  Using cached https://download.pytorch.org/whl/tbb-2021.11.0-py3-none-win_amd64.whl (298 kB)\n",
      "Requirement already satisfied: numpy in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-win_amd64.whl (6.1 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.0%2Bcu121-cp311-cp311-win_amd64.whl (6.1 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-win_amd64.whl (5.8 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp311-cp311-win_amd64.whl (5.7 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.0%2Bcu121-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from jinja2->torch==2.3.1+cu121) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\rag_study_project\\.venv-torch\\lib\\site-packages (from sympy->torch==2.3.1+cu121) (1.3.0)\n",
      "Installing collected packages: tbb, intel-openmp, mkl, torch, torchvision, torchaudio\n",
      "\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   ------------- -------------------------- 2/6 [mkl]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "  Attempting uninstall: torchvision\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "    Found existing installation: torchvision 0.19.0+cu121\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "    Uninstalling torchvision-0.19.0+cu121:\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "      Successfully uninstalled torchvision-0.19.0+cu121\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "  Attempting uninstall: torchaudio\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "    Found existing installation: torchaudio 2.4.0+cu121\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "    Uninstalling torchaudio-2.4.0+cu121:\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "      Successfully uninstalled torchaudio-2.4.0+cu121\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   ---------------------------------------- 6/6 [torchaudio]\n",
      "\n",
      "Successfully installed intel-openmp-2021.4.0 mkl-2021.4.0 tbb-2021.11.0 torch-2.3.1+cu121 torchaudio-2.3.1+cu121 torchvision-0.18.1+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.3.1+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f80dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information:\n",
      "--------------------------------------------------\n",
      "Platform: Windows 10\n",
      "Python version: 3.11.9\n",
      "PyTorch version: 2.3.1+cu121\n",
      "CUDA available: True\n",
      "\n",
      "GPU Information:\n",
      "--------------------------------------------------\n",
      "NVIDIA GPU detected:\n",
      "\n",
      "Sat Aug 30 00:47:48 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.97                 Driver Version: 580.97         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   44C    P8            N/A  /  115W |    1152MiB /   8188MiB |      5%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1236    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A            1536    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            2892    C+G   ...0.3405.119\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            4248    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            6384    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            7248    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A            7928    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A            8548    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A            9756    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10552    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           11272    C+G   ...crosoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           12504    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13140    C+G   ...cord\\app-1.0.9205\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           14384      C   ...s\\Python\\Python311\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           15268    C+G   ...ef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A           15412    C+G   ...al\\Programs\\Notion\\Notion.exe      N/A      |\n",
      "|    0   N/A  N/A           16496    C+G   ...0.3405.119\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           16580    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           16884    C+G   ...8wekyb3d8bbwe\\WebViewHost.exe      N/A      |\n",
      "|    0   N/A  N/A           19228    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           20888    C+G   ...64__8wekyb3d8bbwe\\Copilot.exe      N/A      |\n",
      "|    0   N/A  N/A           20908    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # Check if nvidia-smi is available\n",
    "        nvidia_smi = subprocess.check_output(\"nvidia-smi\", shell=True)\n",
    "        print(\"NVIDIA GPU detected:\\n\")\n",
    "        print(nvidia_smi.decode())\n",
    "        return True\n",
    "    except:\n",
    "        print(\"No NVIDIA GPU detected or nvidia-smi not found\")\n",
    "        return False\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(\"\\nGPU Information:\")\n",
    "print(\"-\" * 50)\n",
    "get_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a0fb0",
   "metadata": {},
   "source": [
    "# 1. RAG - Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e154ed5",
   "metadata": {},
   "source": [
    "## 1.1 Data Process: text over page, then split the sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb610d6",
   "metadata": {},
   "source": [
    "### 1.1.1 download pdf and simple process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ed120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]File human-nutrution-text.pdf already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Get PDF document path\n",
    "pdf_path = \"human-nutrution-text.pdf\"\n",
    "\n",
    "# Download the PDF\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(\"[INFO]File doesn't exist Downloading...\")\n",
    "    \n",
    "    #Enter the URL of the PDF\n",
    "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "    \n",
    "    #The local filename to save the downloaded file\n",
    "    filename = pdf_path\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        #Open the file and save it\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"[INFO]File downloaded and saved as {filename}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"[INFO]Failed to download file. Status code: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"[INFO]File {pdf_path} already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c173d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1208it [00:00, 1485.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "try:\n",
    "    import fitz\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install PyMuPDF\n",
    "    import fitz\n",
    "    \n",
    "def text_formaater(text: str) -> str:\n",
    "    \"\"\"Performs. minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# read pdf file in list[dict]\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formaater(text= text)\n",
    "        pages_and_texts.append({\"page_number\": page_number -41, \n",
    "                               \"page_char_count\": len(text), \n",
    "                               \"page_word_count\": len(text.split(\" \")),\n",
    "                               \"page_sentence_count\" : len(text.split(\". \")),\n",
    "                               \"page_token_count\": len(text)/4, # Rough estimate of tokens\n",
    "                               \"text\":text\n",
    "                               })\n",
    "        \n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580aa8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>459</td>\n",
       "      <td>745</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>186.25</td>\n",
       "      <td>Learning Activities  Technology Note: The seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>460</td>\n",
       "      <td>1958</td>\n",
       "      <td>337</td>\n",
       "      <td>19</td>\n",
       "      <td>489.50</td>\n",
       "      <td>The Atom  UNIVERSITY OF HAWAII AT MNOA FOOD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>461</td>\n",
       "      <td>1339</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>334.75</td>\n",
       "      <td>Image by  DoSiDo / CC  BY-SA 3.0  Atoms and mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "500          459              745              120                    4   \n",
       "501          460             1958              337                   19   \n",
       "502          461             1339              230                   12   \n",
       "\n",
       "     page_token_count                                               text  \n",
       "500            186.25  Learning Activities  Technology Note: The seco...  \n",
       "501            489.50  The Atom  UNIVERSITY OF HAWAII AT MNOA FOOD ...  \n",
       "502            334.75  Image by  DoSiDo / CC  BY-SA 3.0  Atoms and mo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count      1208.00          1208.00          1208.00              1208.00   \n",
       "mean        562.50          1148.00           198.30                 9.97   \n",
       "std         348.86           560.38            95.76                 6.19   \n",
       "min         -41.00             0.00             1.00                 1.00   \n",
       "25%         260.75           762.00           134.00                 4.00   \n",
       "50%         562.50          1231.50           214.50                10.00   \n",
       "75%         864.25          1603.50           271.00                14.00   \n",
       "max        1166.00          2308.00           429.00                32.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1208.00  \n",
       "mean             287.00  \n",
       "std              140.10  \n",
       "min                0.00  \n",
       "25%              190.50  \n",
       "50%              307.88  \n",
       "75%              400.88  \n",
       "max              577.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "#view some of the pages and texts\n",
    "#display(random.sample(pages_and_texts, k=3))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "display(df[500:503])\n",
    "display(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6e246",
   "metadata": {},
   "source": [
    "### 1.1.2 split sentence by using spacy (nlp tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2827ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: This is a sentence. This is another one. And this is the last one.\n",
      "After split: [This is a sentence., This is another one., And this is the last one.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from spacy.lang.en import English\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install spacy\n",
    "    from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "## example for sentence splitting\n",
    "test_sentences = \"This is a sentence. This is another one. And this is the last one.\"\n",
    "doc = nlp(test_sentences)\n",
    "print(f\"Original: {test_sentences}\")\n",
    "print(f\"After split: {list(doc.sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b34744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1208/1208 [00:01<00:00, 1040.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 712,\n",
       "  'page_char_count': 1834,\n",
       "  'page_word_count': 340,\n",
       "  'page_sentence_count': 19,\n",
       "  'page_token_count': 458.5,\n",
       "  'text': 'EAR values become the scientific foundation upon which RDA  values are set.  2. Recommended Daily Allowances. Once the EAR of a nutrient  has been established, the RDA can be mathematically  determined. While the EAR is set at a point that meets the  needs of half the population, RDA values are set to meet the  needs of the vast majority (97 to 98 percent) of the target  healthy population. It is important to note that RDAs are not  the same thing as individual nutritional requirements. The  actual nutrient needs of a given individual will be different  than the RDA. However, since we know that 97 to 98 percent of  the populations needs are met by the RDA, we can assume that  if a person is consuming the RDA of a given nutrient, they are  most likely meeting their nutritional need for that nutrient.  The important thing to remember is that the RDA is meant as a  recommendation and meeting the RDA means it is very likely  that you are meeting your actual requirement for that nutrient.  Understanding the Difference  There is a distinct difference between a requirement and a  recommendation. For instance, the DRI for vitamin D is a  recommended 600 international units each day. However, in order  to find out your true personal requirements for vitamin D, a blood  test is necessary. The blood test will provide an accurate reading  from which a medical professional can gauge your required daily  vitamin D amounts. This may be considerably more or less than the  DRI, depending on what your level actually is.  1. Adequate Intake. AIs are created for nutrients when there is  insufficient consistent scientific evidence to set an EAR for the  entire population. As with RDAs, AIs can be used as nutrient- intake goals for a given nutrient. For example, there has not  712  |  Understanding Dietary Reference Intakes',\n",
       "  'sentences': ['EAR values become the scientific foundation upon which RDA  values are set.',\n",
       "   ' 2.',\n",
       "   'Recommended Daily Allowances.',\n",
       "   'Once the EAR of a nutrient  has been established, the RDA can be mathematically  determined.',\n",
       "   'While the EAR is set at a point that meets the  needs of half the population, RDA values are set to meet the  needs of the vast majority (97 to 98 percent) of the target  healthy population.',\n",
       "   'It is important to note that RDAs are not  the same thing as individual nutritional requirements.',\n",
       "   'The  actual nutrient needs of a given individual will be different  than the RDA.',\n",
       "   'However, since we know that 97 to 98 percent of  the populations needs are met by the RDA, we can assume that  if a person is consuming the RDA of a given nutrient, they are  most likely meeting their nutritional need for that nutrient.',\n",
       "   ' The important thing to remember is that the RDA is meant as a  recommendation and meeting the RDA means it is very likely  that you are meeting your actual requirement for that nutrient.',\n",
       "   ' Understanding the Difference  There is a distinct difference between a requirement and a  recommendation.',\n",
       "   'For instance, the DRI for vitamin D is a  recommended 600 international units each day.',\n",
       "   'However, in order  to find out your true personal requirements for vitamin D, a blood  test is necessary.',\n",
       "   'The blood test will provide an accurate reading  from which a medical professional can gauge your required daily  vitamin D amounts.',\n",
       "   'This may be considerably more or less than the  DRI, depending on what your level actually is.',\n",
       "   ' 1.',\n",
       "   'Adequate Intake.',\n",
       "   'AIs are created for nutrients when there is  insufficient consistent scientific evidence to set an EAR for the  entire population.',\n",
       "   'As with RDAs, AIs can be used as nutrient- intake goals for a given nutrient.',\n",
       "   'For example, there has not  712  |  Understanding Dietary Reference Intakes'],\n",
       "  'page_sentence_count_spacy': 19}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    # Process the text with spaCy\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    \n",
    "    #make sure to convert sentences to string\n",
    "    item[\"sentences\"] = [str(sentence)for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Add the sentence count to the item\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])\n",
    "    \n",
    "    \n",
    "#view some of the pages and texts\n",
    "random.sample(pages_and_texts, k=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da1e47",
   "metadata": {},
   "source": [
    "## 1.2 Chunk the sentence together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1727d3",
   "metadata": {},
   "source": [
    "### 1.2.1 chunk sentence function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "141edbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sentence_chunk_size = 10\n",
    "\n",
    "## chunking function\n",
    "def split_list(input_list : list[str],\n",
    "               slice_size : int= num_sentence_chunk_size) -> list[list[str]]:\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "#to check if the function works apporpiately\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9825443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1208/1208 [00:00<00:00, 302075.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after chunking:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 496,\n",
       "  'page_char_count': 1805,\n",
       "  'page_word_count': 283,\n",
       "  'page_sentence_count': 19,\n",
       "  'page_token_count': 451.25,\n",
       "  'text': 'that have more recently modernized, industrialized, and urbanized  are experiencing a surge in their overweight and obese populations.  China, the most populous country in the world, now has more than  215 million people, approximately one-fifth of their population, that  are considered overweight or obese.4  The increase in Chinas waistline is partly attributed to changes  in the traditional diet, more sedentary lives, and a massive increase  in motor vehicle use. Moreover, Chinas recent famines in the 1950s,  which affected the poor and lower classes to a greater extent than  the upper class, have sanctioned lax social attitudes toward body  fat and reinspired the age-old Chinese belief that excess body fat  represents health and prosperity.  One of the worst statistics regarding overweight and obesity in  China is that more than ten million adolescents between ages  seventeen and eighteen were overweight in 2000, which is twenty- eight times the number that were overweight in 1985.5  The associated diseases of overweight and obesity happen over  many years, and signs and symptoms commonly take decades to  manifest. With Chinas younger population and other developed  countries experiencing a dramatic weight increase, the associated  chronic diseases will come about much earlier in life than in  previous generations. This will put an even greater burden on  society.  4.\\xa0Wu Y. (2006). Overweight and Obesity in China. British  Medical Journal, 333(7564), 362-363.  https://www.ncbi.nlm.nih.gov/pmc/articles/ PMC1550451/. Accessed September 22, 2017.  5.\\xa0Wu Y. (2006). \\xa0Overweight and Obesity in China. British  Medical Journal, 333(7564), 362-363.  https://www.ncbi.nlm.nih.gov/pmc/articles/ PMC1550451/. Accessed September 22, 2017.  496  |  Factors Affecting Energy Expenditure',\n",
       "  'sentences': ['that have more recently modernized, industrialized, and urbanized  are experiencing a surge in their overweight and obese populations.',\n",
       "   ' China, the most populous country in the world, now has more than  215 million people, approximately one-fifth of their population, that  are considered overweight or obese.4  The increase in Chinas waistline is partly attributed to changes  in the traditional diet, more sedentary lives, and a massive increase  in motor vehicle use.',\n",
       "   'Moreover, Chinas recent famines in the 1950s,  which affected the poor and lower classes to a greater extent than  the upper class, have sanctioned lax social attitudes toward body  fat and reinspired the age-old Chinese belief that excess body fat  represents health and prosperity.',\n",
       "   ' One of the worst statistics regarding overweight and obesity in  China is that more than ten million adolescents between ages  seventeen and eighteen were overweight in 2000, which is twenty- eight times the number that were overweight in 1985.5  The associated diseases of overweight and obesity happen over  many years, and signs and symptoms commonly take decades to  manifest.',\n",
       "   'With Chinas younger population and other developed  countries experiencing a dramatic weight increase, the associated  chronic diseases will come about much earlier in life than in  previous generations.',\n",
       "   'This will put an even greater burden on  society.',\n",
       "   ' 4.',\n",
       "   '\\xa0Wu Y. (2006).',\n",
       "   'Overweight and Obesity in China.',\n",
       "   'British  Medical Journal, 333(7564), 362-363.',\n",
       "   ' https://www.ncbi.nlm.nih.gov/pmc/articles/ PMC1550451/. Accessed September 22, 2017.',\n",
       "   ' 5.',\n",
       "   '\\xa0Wu Y. (2006).',\n",
       "   '\\xa0Overweight and Obesity in China.',\n",
       "   'British  Medical Journal, 333(7564), 362-363.',\n",
       "   ' https://www.ncbi.nlm.nih.gov/pmc/articles/ PMC1550451/. Accessed September 22, 2017.',\n",
       "   ' 496  |  Factors Affecting Energy Expenditure'],\n",
       "  'page_sentence_count_spacy': 17,\n",
       "  'sentence_chunks': [['that have more recently modernized, industrialized, and urbanized  are experiencing a surge in their overweight and obese populations.',\n",
       "    ' China, the most populous country in the world, now has more than  215 million people, approximately one-fifth of their population, that  are considered overweight or obese.4  The increase in Chinas waistline is partly attributed to changes  in the traditional diet, more sedentary lives, and a massive increase  in motor vehicle use.',\n",
       "    'Moreover, Chinas recent famines in the 1950s,  which affected the poor and lower classes to a greater extent than  the upper class, have sanctioned lax social attitudes toward body  fat and reinspired the age-old Chinese belief that excess body fat  represents health and prosperity.',\n",
       "    ' One of the worst statistics regarding overweight and obesity in  China is that more than ten million adolescents between ages  seventeen and eighteen were overweight in 2000, which is twenty- eight times the number that were overweight in 1985.5  The associated diseases of overweight and obesity happen over  many years, and signs and symptoms commonly take decades to  manifest.',\n",
       "    'With Chinas younger population and other developed  countries experiencing a dramatic weight increase, the associated  chronic diseases will come about much earlier in life than in  previous generations.',\n",
       "    'This will put an even greater burden on  society.',\n",
       "    ' 4.',\n",
       "    '\\xa0Wu Y. (2006).',\n",
       "    'Overweight and Obesity in China.',\n",
       "    'British  Medical Journal, 333(7564), 362-363.'],\n",
       "   [' https://www.ncbi.nlm.nih.gov/pmc/articles/ PMC1550451/. Accessed September 22, 2017.',\n",
       "    ' 5.',\n",
       "    '\\xa0Wu Y. (2006).',\n",
       "    '\\xa0Overweight and Obesity in China.',\n",
       "    'British  Medical Journal, 333(7564), 362-363.',\n",
       "    ' https://www.ncbi.nlm.nih.gov/pmc/articles/ PMC1550451/. Accessed September 22, 2017.',\n",
       "    ' 496  |  Factors Affecting Energy Expenditure']],\n",
       "  'num_chunks': 2}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>sentence_chunks</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "      <td>[Human Nutrition: 2020 Edition]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Human Nutrition: 2020 Edition]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39</td>\n",
       "      <td>320</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
       "      <td>[Human Nutrition: 2020  Edition  UNIVERSITY OF...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Human Nutrition: 2020  Edition  UNIVERSITY O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "      <td>[Human Nutrition: 2020 Edition by University o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Human Nutrition: 2020 Edition by University ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37</td>\n",
       "      <td>797</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>199.25</td>\n",
       "      <td>Contents  Preface  University of Hawaii at M...</td>\n",
       "      <td>[Contents  Preface  University of Hawaii at M...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[Contents  Preface  University of Hawaii at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "0          -41               29                4                    1   \n",
       "1          -40                0                1                    1   \n",
       "2          -39              320               54                    1   \n",
       "3          -38              212               32                    1   \n",
       "4          -37              797              145                    2   \n",
       "\n",
       "   page_token_count                                               text  \\\n",
       "0              7.25                      Human Nutrition: 2020 Edition   \n",
       "1              0.00                                                      \n",
       "2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...   \n",
       "3             53.00  Human Nutrition: 2020 Edition by University of...   \n",
       "4            199.25  Contents  Preface  University of Hawaii at M...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0                    [Human Nutrition: 2020 Edition]   \n",
       "1                                                 []   \n",
       "2  [Human Nutrition: 2020  Edition  UNIVERSITY OF...   \n",
       "3  [Human Nutrition: 2020 Edition by University o...   \n",
       "4  [Contents  Preface  University of Hawaii at M...   \n",
       "\n",
       "   page_sentence_count_spacy  \\\n",
       "0                          1   \n",
       "1                          0   \n",
       "2                          1   \n",
       "3                          1   \n",
       "4                          2   \n",
       "\n",
       "                                     sentence_chunks  num_chunks  \n",
       "0                  [[Human Nutrition: 2020 Edition]]           1  \n",
       "1                                                 []           0  \n",
       "2  [[Human Nutrition: 2020  Edition  UNIVERSITY O...           1  \n",
       "3  [[Human Nutrition: 2020 Edition by University ...           1  \n",
       "4  [[Contents  Preface  University of Hawaii at ...           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count      1208.00          1208.00          1208.00              1208.00   \n",
       "mean        562.50          1148.00           198.30                 9.97   \n",
       "std         348.86           560.38            95.76                 6.19   \n",
       "min         -41.00             0.00             1.00                 1.00   \n",
       "25%         260.75           762.00           134.00                 4.00   \n",
       "50%         562.50          1231.50           214.50                10.00   \n",
       "75%         864.25          1603.50           271.00                14.00   \n",
       "max        1166.00          2308.00           429.00                32.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           1208.00                    1208.00     1208.00  \n",
       "mean             287.00                      10.32        1.53  \n",
       "std              140.10                       6.30        0.64  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              190.50                       5.00        1.00  \n",
       "50%              307.88                      10.00        1.00  \n",
       "75%              400.88                      15.00        2.00  \n",
       "max              577.00                      28.00        3.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"]=split_list(item[\"sentences\"])\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])\n",
    "    \n",
    "print(f\"after chunking:\")\n",
    "display(random.sample(pages_and_texts, k=1))\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "display(df.head())\n",
    "display(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a7fda",
   "metadata": {},
   "source": [
    "### 1.2.2 groupby page[chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d04627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1208/1208 [00:00<00:00, 40266.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        #Join the sentences together into a paragraph-like structure, i.e. join the list of sentence into one paragraph\n",
    "        # list to string\n",
    "        joined_sentences_chunk = \"\".join(sentence_chunk).replace(\"  \",\" \").strip()\n",
    "        joined_sentences_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentences_chunk) # \".A\" to \". A\"\n",
    "\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentences_chunk\n",
    "        \n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentences_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentences_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentences_chunk)/4     # Rough estimate of tokens\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "        \n",
    "len(pages_and_chunks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d93bdbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>583.38</td>\n",
       "      <td>734.44</td>\n",
       "      <td>112.33</td>\n",
       "      <td>183.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>347.79</td>\n",
       "      <td>447.54</td>\n",
       "      <td>71.22</td>\n",
       "      <td>111.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.50</td>\n",
       "      <td>315.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>586.00</td>\n",
       "      <td>746.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>186.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>890.00</td>\n",
       "      <td>1118.50</td>\n",
       "      <td>173.00</td>\n",
       "      <td>279.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>1831.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>457.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1843.00           1843.00           1843.00            1843.00\n",
       "mean        583.38            734.44            112.33             183.61\n",
       "std         347.79            447.54             71.22             111.89\n",
       "min         -41.00             12.00              3.00               3.00\n",
       "25%         280.50            315.00             44.00              78.75\n",
       "50%         586.00            746.00            114.00             186.50\n",
       "75%         890.00           1118.50            173.00             279.62\n",
       "max        1166.00           1831.00            297.00             457.75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(pages_and_chunks)\n",
    "df.head()\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9dbd2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk token: 28.75 ||sentence chunk: Image by FDA/ Changes to the Nutrition Facts Label Figure 12.5 Food Serving Sizes 728 | Discovering Nutrition Facts\n",
      "chunk token: 24.75 ||sentence chunk: http://www.ajcn.org/content/87/1/64.long. Accessed September 22, 2017. 554 | Water-Soluble Vitamins\n",
      "chunk token: 25.5 ||sentence chunk: http://www.ajcn.org/cgi/ pmidlookup?view=long&pmid=10197575. Accessed October 6, 2017. 640 | Magnesium\n",
      "chunk token: 16.5 ||sentence chunk: Table 4.6 Sweeteners Carbohydrates and Personal Diet Choices | 281\n",
      "chunk token: 12.75 ||sentence chunk: PARTVIII CHAPTER 8. ENERGY Chapter 8. Energy | 451\n"
     ]
    }
   ],
   "source": [
    "min_token_length = 30\n",
    "## almost all of the chunks with under 30 tokens are not useful\n",
    "for row in df[df[\"chunk_token_count\"]< min_token_length].sample(5).iterrows():\n",
    "    print(f\"chunk token: {row[1]['chunk_token_count']} ||sentence chunk: {row[1]['sentence_chunk']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddceae",
   "metadata": {},
   "source": [
    "### 1.2.3 filter out the chunks with under 30 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "243ca8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -39,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAII AT MNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE',\n",
       "  'chunk_char_count': 308,\n",
       "  'chunk_word_count': 42,\n",
       "  'chunk_token_count': 77.0},\n",
       " {'page_number': -38,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition by University of Hawaii at Mnoa Food Science and Human Nutrition Program is licensed under a Creative Commons Attribution 4.0 International License, except where otherwise noted.',\n",
       "  'chunk_char_count': 210,\n",
       "  'chunk_word_count': 30,\n",
       "  'chunk_token_count': 52.5}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1009,\n",
       "  'sentence_chunk': 'PCBs, or polychlorinated biphenyls, are man-made organic compounds that consists of carbon, hydrogen and chlorine. Due to their non-flammability, chemically stable, and high boiling points PCBs were manufactured and used commercially from 1929 until 1979 when it was banned. Like methylmercury, higher concentrations of this contaminant are found in predatory fish. Health effects include complications in physical and neurological development in children, and this compound is potentially a carcinogen. PCB contamination also can affect the immune, reproductive, nervous, and endocrine systems.9 Learning Activities Technology Note: The second edition of the Human Nutrition Open Educational Resource (OER) textbook features interactive learning activities.\\xa0 These activities are Ministry of the Environment, Government of Japan.http://www.env.go.jp/en/chemi/hs/ minamata2002/. Published 2002. Accessed December 21, 2011. 9.\\xa0Learn About Polychlorinated Biphenyls. (2017). US Environmental Protection Agency.',\n",
       "  'chunk_char_count': 1008,\n",
       "  'chunk_word_count': 127,\n",
       "  'chunk_token_count': 252.0}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pages_and_chunks_over_min_token_length = df[df[\"chunk_token_count\"] >= min_token_length].to_dict(orient=\"records\")\n",
    "display(pages_and_chunks_over_min_token_length[:2])\n",
    "random.sample(pages_and_chunks_over_min_token_length, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706fa89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc005a56",
   "metadata": {},
   "source": [
    "## 1.3 Embedding the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f515e",
   "metadata": {},
   "source": [
    "#### 1.3.1 Embedding model download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58083abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path= \"all-mpnet-base-v2\", device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "126a34f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This is a sentence.\n",
      "Embedding(first 5): [ 0.04461046 -0.01864081 -0.00090315  0.02639336 -0.0418851 ]\n",
      "Embedding shape: (768,)\n",
      "Sentence: This is another one.\n",
      "Embedding(first 5): [ 0.02019235  0.0298154   0.00167827 -0.04361509 -0.03454699]\n",
      "Embedding shape: (768,)\n",
      "Sentence: And this is the last one.\n",
      "Embedding(first 5): [ 0.01193439  0.03599297 -0.02380103 -0.0224243   0.02393362]\n",
      "Embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\"This is a sentence.\", \"This is another one.\", \"And this is the last one.\"]\n",
    "\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embedding(first 5): {embedding[:5]}\")\n",
    "    print(f\"Embedding shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52a97500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bc5a4",
   "metadata": {},
   "source": [
    "#### 1.3.2 Embedding chunks one by one with using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b15bb55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1680/1680 [03:07<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 13s, sys: 44.4 s, total: 4min 57s \n",
      " Wall time: 3min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time \n",
    "\n",
    "cpu_run = True\n",
    "\n",
    "if cpu_run:\n",
    "    embedding_model.to(\"cpu\")\n",
    "\n",
    "    for item in tqdm(pages_and_chunks_over_min_token_length):\n",
    "        item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])\n",
    "        item[\"embedding_shape\"] = item[\"embedding\"].shape\n",
    "    \n",
    "print(\"CPU times: user 4min 13s, sys: 44.4 s, total: 4min 57s \\n Wall time: 3min 30s\")## on MacBook Pro M2 Pro 16GB RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5d48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1680/1680 [00:26<00:00, 63.76it/s]\n"
     ]
    }
   ],
   "source": [
    "#%%time \n",
    "##with GPU\n",
    "cuda_run = True\n",
    "\n",
    "if cuda_run:\n",
    "    embedding_model.to(\"cuda\")\n",
    "\n",
    "    for item in tqdm(pages_and_chunks_over_min_token_length):\n",
    "        item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])\n",
    "        item[\"embedding_shape\"] = item[\"embedding\"].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc723d7",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.3.3 Save embeddings to file ( Don't run it if the embeddings is not ran above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a6585e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_length)\n",
    "embeddings_df_save_path = \"text_chunks_embeddings_df.csv\"\n",
    "text_chunks_embeddings_df.to_csv(embeddings_df_save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff24b784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>embedding_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39</td>\n",
       "      <td>Human Nutrition: 2020 Edition UNIVERSITY OF HA...</td>\n",
       "      <td>308</td>\n",
       "      <td>42</td>\n",
       "      <td>77.00</td>\n",
       "      <td>[ 6.74242675e-02  9.02281329e-02 -5.09549491e-...</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>52.50</td>\n",
       "      <td>[ 5.52156270e-02  5.92139587e-02 -1.66167449e-...</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-37</td>\n",
       "      <td>Contents Preface University of Hawaii at Mno...</td>\n",
       "      <td>766</td>\n",
       "      <td>114</td>\n",
       "      <td>191.50</td>\n",
       "      <td>[ 2.79801972e-02  3.39813679e-02 -2.06426457e-...</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-36</td>\n",
       "      <td>Lifestyles and Nutrition University of Hawaii...</td>\n",
       "      <td>941</td>\n",
       "      <td>142</td>\n",
       "      <td>235.25</td>\n",
       "      <td>[ 6.82566985e-02  3.81275043e-02 -8.46854504e-...</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35</td>\n",
       "      <td>The Cardiovascular System University of Hawai...</td>\n",
       "      <td>998</td>\n",
       "      <td>152</td>\n",
       "      <td>249.50</td>\n",
       "      <td>[ 3.30264494e-02 -8.49768892e-03  9.57159698e-...</td>\n",
       "      <td>(768,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0          -39  Human Nutrition: 2020 Edition UNIVERSITY OF HA...   \n",
       "1          -38  Human Nutrition: 2020 Edition by University of...   \n",
       "2          -37  Contents Preface University of Hawaii at Mno...   \n",
       "3          -36  Lifestyles and Nutrition University of Hawaii...   \n",
       "4          -35  The Cardiovascular System University of Hawai...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               308                42              77.00   \n",
       "1               210                30              52.50   \n",
       "2               766               114             191.50   \n",
       "3               941               142             235.25   \n",
       "4               998               152             249.50   \n",
       "\n",
       "                                           embedding embedding_shape  \n",
       "0  [ 6.74242675e-02  9.02281329e-02 -5.09549491e-...          (768,)  \n",
       "1  [ 5.52156270e-02  5.92139587e-02 -1.66167449e-...          (768,)  \n",
       "2  [ 2.79801972e-02  3.39813679e-02 -2.06426457e-...          (768,)  \n",
       "3  [ 6.82566985e-02  3.81275043e-02 -8.46854504e-...          (768,)  \n",
       "4  [ 3.30264494e-02 -8.49768892e-03  9.57159698e-...          (768,)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import saved file and view\n",
    "\n",
    "text_chunks_embeddings_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_embeddings_df_load.head()\n",
    "\n",
    "\n",
    "# notice saving embeddings data to csv file may not be the best way, \n",
    "# in stead of doing that, vectors database is recommended when the data is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834d2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad8fb0e9",
   "metadata": {},
   "source": [
    "# 2. RAG - Top relevant Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5365e",
   "metadata": {},
   "source": [
    "### 2.1 import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c4ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "embeddings : tensor([[ 0.0674,  0.0902, -0.0051,  ..., -0.0221, -0.0232,  0.0126],\n",
      "        [ 0.0552,  0.0592, -0.0166,  ..., -0.0120, -0.0103,  0.0227],\n",
      "        [ 0.0280,  0.0340, -0.0206,  ..., -0.0054,  0.0213,  0.0313],\n",
      "        ...,\n",
      "        [ 0.0771,  0.0098, -0.0122,  ..., -0.0409, -0.0752, -0.0241],\n",
      "        [ 0.1030, -0.0165,  0.0083,  ..., -0.0574, -0.0283, -0.0295],\n",
      "        [ 0.0864, -0.0125, -0.0113,  ..., -0.0522, -0.0337, -0.0299]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "embeddings shape: torch.Size([1680, 768])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the embeddings from CSV file\n",
    "text_chunks_embeddings_df = pd.read_csv(\"text_chunks_embeddings_df.csv\")\n",
    "\n",
    "#Convert the embeddings from string representation to numpy arrays\n",
    "text_chunks_embeddings_df[\"embedding\"] = text_chunks_embeddings_df[\"embedding\"].apply(\n",
    "    lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \").astype(np.float64)\n",
    ")\n",
    "\n",
    "embeddings = torch.tensor(np.stack(text_chunks_embeddings_df[\"embedding\"].tolist(), \n",
    "                    axis=0)).to(device)\n",
    "\n",
    "\n",
    "print(f\"embeddings : {embeddings}\")\n",
    "print(f\"embeddings shape: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b3060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d83e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y numpy\n",
    "#!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed76518",
   "metadata": {},
   "source": [
    "### 2.2 loading embedding model and doing sematic search pipeline\n",
    "\n",
    "Doing sematic search pipeline with the following steps:\n",
    "1. define query\n",
    "2. embedding the query\n",
    "3. cosine similarity with text embeddings and query embedding\n",
    "4. find top k highest similarity from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a713d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\RAG_study_project\\.venv-torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "try:\n",
    "    if embedding_model is None:\n",
    "        # Load the embedding model\n",
    "        embedding_model = SentenceTransformer(model_name_or_path= \"all-mpnet-base-v2\", device=device)\n",
    "except NameError:\n",
    "    embedding_model = SentenceTransformer(model_name_or_path= \"all-mpnet-base-v2\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdd6a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query: What is the role of carbohydrates in human nutrition?\n",
      "Query embedding shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the role of carbohydrates in human nutrition?\"\n",
    "query_embedding = embedding_model.encode(query, device=device, convert_to_tensor=True).to(torch.float64)\n",
    "\n",
    "print(f\"Enter query: {query}\")\n",
    "print(f\"Query embedding shape: {query_embedding.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8eb5aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1680])\n",
      "top 5 results: tensor([389, 381, 390, 347,  41], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "k=5\n",
    "## Perform semantic search by dot product with no normalization\n",
    "\n",
    "dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "print(dot_scores.shape)\n",
    "\n",
    "top_k = torch.topk(dot_scores, k=k)\n",
    "print(f\"top {k} results: {top_k.indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe13e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ed7185",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f47a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4060', major=8, minor=9, total_memory=8187MB, multi_processor_count=24)\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "## checking local memoery\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_properties(0))\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3257fe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information:\n",
      "--------------------------------------------------\n",
      "Platform: Windows-10-10.0.19045-SP0\n",
      "Processor: Intel64 Family 6 Model 151 Stepping 5, GenuineIntel\n",
      "Physical cores: 6\n",
      "Total cores: 12\n",
      "\n",
      "PyTorch Information:\n",
      "--------------------------------------------------\n",
      "PyTorch Version: 2.3.1+cu121\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.1\n",
      "CUDA Device: NVIDIA GeForce RTX 4060\n",
      "CUDA Device Count: 1\n",
      "Current CUDA Device: 0\n",
      "\n",
      "Testing CUDA with tensor operation:\n",
      "Tensor on CPU:\n",
      "tensor([[0.0441, 0.9991, 0.1038],\n",
      "        [0.9411, 0.0639, 0.7755],\n",
      "        [0.7403, 0.6507, 0.1738],\n",
      "        [0.5913, 0.7138, 0.8563],\n",
      "        [0.9200, 0.7269, 0.4331]])\n",
      "Tensor on GPU:\n",
      "tensor([[0.0441, 0.9991, 0.1038],\n",
      "        [0.9411, 0.0639, 0.7755],\n",
      "        [0.7403, 0.6507, 0.1738],\n",
      "        [0.5913, 0.7138, 0.8563],\n",
      "        [0.9200, 0.7269, 0.4331]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "# System info\n",
    "print(\"System Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Physical cores: {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"Total cores: {psutil.cpu_count()}\")\n",
    "\n",
    "# PyTorch and CUDA info\n",
    "print(\"\\nPyTorch Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA Device: {torch.cuda.current_device()}\")\n",
    "    # Test CUDA with a small tensor operation\n",
    "    x = torch.rand(5, 3)\n",
    "    print(\"\\nTesting CUDA with tensor operation:\")\n",
    "    print(f\"Tensor on CPU:\\n{x}\")\n",
    "    x = x.cuda()\n",
    "    print(f\"Tensor on GPU:\\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c9b129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor: Intel64 Family 6 Model 151 Stepping 5, GenuineIntel\n",
      "Machine: AMD64\n",
      "Platform: Windows-10-10.0.19045-SP0\n",
      "CPU cores (physical): 6\n",
      "CPU cores (total): 12\n",
      "CPU frequency (MHz): <module 'psutil' from 'c:\\\\RAG_study_project\\\\.venv-torch\\\\Lib\\\\site-packages\\\\psutil\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import psutil\n",
    "\n",
    "print(\"Processor:\", platform.processor())\n",
    "print(\"Machine:\", platform.machine())\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"CPU cores (physical):\", psutil.cpu_count(logical=False))\n",
    "print(\"CPU cores (total):\", psutil.cpu_count(logical=True))\n",
    "print(\"CPU frequency (MHz):\", psutil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea63d1",
   "metadata": {},
   "source": [
    "### 2.3 show the pages for the result with following steps:\n",
    "\n",
    "1. open the pdf in image\n",
    "2. show the image with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "557ee512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fitz\n",
    "#!pip install frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44b6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def pdf_img_show(num_page: int):\n",
    "\n",
    "    pdf_path = \"human-nutrution-text.pdf\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(num_page+41)\n",
    "\n",
    "    img = page.get_pixmap(dpi=300)\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    img_array = np.frombuffer(img.samples_mv, dtype=np.uint8).reshape((img.h, img.w, img.n))\n",
    "    \n",
    "    plt.figure(figsize= (13,10))\n",
    "    plt.imshow(img_array)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "#pdf_img_show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6ae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f6b89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : What is the role of carbohydrates in human nutrition?\n",
      "\n",
      "Top 1 relevant result (from page299): \n",
      "Without energy none of the other life processes are performed\n",
      " Although our bodies can synthesize glucose it comes at the cost of protein destruction\n",
      " As with all nutrients though, carbohydrates are to be consumed in moderation as having too much or too little in the diet may lead to health problems\n",
      " Learning Activities Technology Note: The second edition of the Human Nutrition Open Educational Resource (OER) textbook features interactive learning activities\n",
      " These activities are available in the web-based textbook and not available in the downloadable versions (EPUB, Digital PDF, Print_PDF, or Open Document)\n",
      " 258 | The Functions of Carbohydrates in the Body\n",
      "\n",
      "\n",
      "\n",
      "Top 2 relevant result (from page294): \n",
      "The Functions of Carbohydrates in the Body UNIVERSITY OF HAWAII AT MNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM AND HUMAN NUTRITION PROGRAM There are five primary functions of carbohydrates in the human body\n",
      " They are energy production, energy storage, building macromolecules, sparing protein, and assisting in lipid metabolism\n",
      " Energy Production The primary role of carbohydrates is to supply energy to all cells in the body\n",
      " Many cells prefer glucose as a source of energy versus other compounds like fatty acids\n",
      " Some cells, such as red blood cells, are only able to produce cellular energy from glucose\n",
      " The brain is also highly sensitive to low blood-glucose levels because it uses only glucose to produce energy and function (unless under extreme starvation conditions)\n",
      " About 70 percent of the glucose entering the body from digestion is redistributed (by the liver) back into the blood for use by other tissues\n",
      " Cells that require energy remove the glucose from the blood with a transport protein in their membranes\n",
      " The energy from glucose comes from the chemical bonds between the carbon atoms\n",
      " Sunlight energy was required to produce these high-energy bonds in the process of photosynthesis\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 3 relevant result (from page300): \n",
      "Learning activities may be used across various mobile devices, however, for the best user experience it is strongly recommended that users complete these activities using a desktop or laptop computer and in Google Chrome\n",
      "  An interactive or media element has been excluded from this version of the text\n",
      " You can view it online here: http://pressbooks\n",
      "oer\n",
      "hawaii\n",
      "edu/ humannutrition2/?p=187  An interactive or media element has been excluded from this version of the text\n",
      " You can view it online here: http://pressbooks\n",
      "oer\n",
      "hawaii\n",
      "edu/ humannutrition2/?p=187 The Functions of Carbohydrates in the Body | 259\n",
      "\n",
      "\n",
      "\n",
      "Top 4 relevant result (from page271): \n",
      " Describe the different types of simple and complex carbohydrates  Describe the process of carbohydrate digestion and absorption  Describe the functions of carbohydrates in the body  Describe the bodys carbohydrate needs and how personal choices can lead to health benefits or consequences Throughout history, carbohydrates have and continue to be a major source of peoples diets worldwide\n",
      " In ancient Hawaii the Hawaiians obtained the majority of their calories from carbohydrate rich plants like the uala (sweet potato), ulu (breadfruit) and kalo (taro)\n",
      " For example, mashed kalo or poi was a staple to meals for Hawaiians\n",
      " Research suggests that almost 78 percent of the diet was made up of these fiber rich carbohydrate foods\n",
      "1 Carbohydrates are the perfect nutrient to meet your bodys nutritional needs\n",
      " They nourish your brain and nervous system, provide energy to all of your cells when within proper caloric limits, and help keep your body fit and lean\n",
      " Specifically, digestible carbohydrates provide bulk in foods, vitamins, and minerals, while 1\n",
      "Fujita R, Braun KL, Hughes CK\n",
      " (2004)\n",
      " The traditional Hawaiian diet: a review of the literature\n",
      " Pacific Health Dialogue, 11(2)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 5 relevant result (from page45): \n",
      "Learning Objectives By the end of this chapter, you will be able to:  Describe basic concepts in nutrition  Describe factors that affect your nutritional needs  Describe the importance of research and scientific methods to understanding nutrition What are Nutrients? The foods we eat contain nutrients\n",
      " Nutrients are substances required by the body to perform its basic functions\n",
      " Nutrients must be obtained from our diet, since the human body does not synthesize or produce them\n",
      " Nutrients have one or more of three basic functions: they provide energy, contribute to body structure, and/or regulate chemical processes in the body\n",
      " These basic functions allow us to detect and respond to environmental surroundings, move, excrete wastes, respire (breathe), grow, and reproduce\n",
      " There are six classes of nutrients required for the body to function and maintain overall health\n",
      " These are carbohydrates, lipids, proteins, water, vitamins, and minerals\n",
      " Foods also contain non-nutrients that may be harmful (such as natural toxins common in plant foods and additives like some dyes and preservatives) or beneficial (such as antioxidants)\n",
      " 4 | Introduction\n",
      "\n",
      "\n",
      "\n",
      "Total token count: 1207.75\n",
      "Total word count: 742\n"
     ]
    }
   ],
   "source": [
    "# show the top k result in text\n",
    "top_k_embeddings = embeddings[top_k.indices]\n",
    "\n",
    "print(f\"Query : {query}\\n\")\n",
    "\n",
    "total_token_count = 0\n",
    "total_word_count = 0\n",
    "\n",
    "for i, idx in enumerate(top_k.indices):\n",
    "    page_number = text_chunks_embeddings_df[\"page_number\"].iloc[int(idx)]+41\n",
    "    print(f\"Top {i+1} relevant result (from page{page_number}): \")\n",
    "    \n",
    "    text_chunks = text_chunks_embeddings_df[\"sentence_chunk\"].iloc[int(idx)]\n",
    "    total_token_count += text_chunks_embeddings_df[\"chunk_token_count\"].iloc[int(idx)]\n",
    "    total_word_count += text_chunks_embeddings_df[\"chunk_word_count\"].iloc[int(idx)]\n",
    "    \n",
    "    for sentence in [ n for n in text_chunks.split(\".\")]:\n",
    "        print(sentence)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "print(f\"Total token count: {total_token_count}\")\n",
    "print(f\"Total word count: {total_word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1a460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrival_search(query : str,\n",
    "             top_k : int = 5,\n",
    "             embeddings : torch.tensor = embeddings,\n",
    "             embedding_model : SentenceTransformer = embedding_model,\n",
    "             \n",
    "             device: str = device):\n",
    "    \n",
    "    #step 1: Turn query to embedding\n",
    "    query_embedding = embedding_model.encode(query, device=device, convert_to_tensor=True).to(torch.float64)\n",
    "    \n",
    "    #step 2: Find top k <query_embedding, embeddings>\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    top_k = torch.topk(dot_scores, k=top_k+1)\n",
    "    \n",
    "    #step 3: text_chunk_df[top_k.indices]\n",
    "    indices = top_k.indices\n",
    "    scores = top_k.values\n",
    "    \n",
    "    return indices, scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9625d5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 10 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([389, 381, 390, 347,  41,  47], device='cuda:0'),\n",
       " tensor([0.7348, 0.7205, 0.7136, 0.6789, 0.6650, 0.6602], device='cuda:0',\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "retrival_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ddd4aa",
   "metadata": {},
   "source": [
    "### 2.3 Funtionalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f3f6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_top_results(query : str,        \n",
    "                      top_k : int = 5,\n",
    "                      embeddings : torch.tensor = embeddings,\n",
    "                      embedding_model : SentenceTransformer = embedding_model,\n",
    "                      text_chunk_df : pd.DataFrame = text_chunks_embeddings_df,\n",
    "                      show_result = True):\n",
    "    \n",
    "    ## find top k relevant text chunk\n",
    "    indices , scores = retrival_search(query, top_k, embeddings, embedding_model)\n",
    "    \n",
    "    top_k_relevant_text = [text_chunk_df[\"sentence_chunk\"].iloc[int(idx)] for idx in indices]\n",
    "    \n",
    "    if show_result:\n",
    "        print(f\"Query: {query}\\n\")\n",
    "        print(\"---\"*40)\n",
    "    \n",
    "    relevant_texts = list()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        text = text_chunk_df[\"sentence_chunk\"].iloc[int(idx)]\n",
    "        relevant_texts.append(text)\n",
    "        page_number = int(text_chunks_embeddings_df[\"page_number\"].iloc[int(idx)])\n",
    "        \n",
    "        if show_result:\n",
    "            pdf_img_show(page_number)\n",
    "            print(f\"Top {i+1} relevant text\")\n",
    "            print(textwrap.fill(text, 80)+\"\\n\")\n",
    "            print(f\"Source page: {page_number}\")\n",
    "            print(\"---\"*40)\n",
    "        \n",
    "    return relevant_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680b77f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Without energy none of the other life processes are performed. Although our bodies can synthesize glucose it comes at the cost of protein destruction. As with all nutrients though, carbohydrates are to be consumed in moderation as having too much or too little in the diet may lead to health problems. Learning Activities Technology Note: The second edition of the Human Nutrition Open Educational Resource (OER) textbook features interactive learning activities.\\xa0 These activities are available in the web-based textbook and not available in the downloadable versions (EPUB, Digital PDF, Print_PDF, or Open Document). 258 | The Functions of Carbohydrates in the Body',\n",
       " 'The Functions of Carbohydrates in the Body UNIVERSITY OF HAWAII AT MNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM AND HUMAN NUTRITION PROGRAM There are five primary functions of carbohydrates in the human body. They are energy production, energy storage, building macromolecules, sparing protein, and assisting in lipid metabolism. Energy Production The primary role of carbohydrates is to supply energy to all cells in the body. Many cells prefer glucose as a source of energy versus other compounds like fatty acids. Some cells, such as red blood cells, are only able to produce cellular energy from glucose. The brain is also highly sensitive to low blood-glucose levels because it uses only glucose to produce energy and function (unless under extreme starvation conditions). About 70 percent of the glucose entering the body from digestion is redistributed (by the liver) back into the blood for use by other tissues. Cells that require energy remove the glucose from the blood with a transport protein in their membranes. The energy from glucose comes from the chemical bonds between the carbon atoms. Sunlight energy was required to produce these high-energy bonds in the process of photosynthesis.',\n",
       " 'Learning activities may be used across various mobile devices, however, for the best user experience it is strongly recommended that users complete these activities using a desktop or laptop computer and in Google Chrome. \\xa0 An interactive or media element has been excluded from this version of the text. You can view it online here: http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=187 \\xa0 An interactive or media element has been excluded from this version of the text. You can view it online here: http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=187 The Functions of Carbohydrates in the Body | 259',\n",
       " ' Describe the different types of simple and complex carbohydrates  Describe the process of carbohydrate digestion and absorption  Describe the functions of carbohydrates in the body  Describe the bodys carbohydrate needs and how personal choices can lead to health benefits or consequences Throughout history, carbohydrates have and continue to be a major source of peoples diets worldwide. In ancient Hawaii the Hawaiians obtained the majority of their calories from carbohydrate rich plants like the uala (sweet potato), ulu (breadfruit) and kalo (taro). For example, mashed kalo or poi was a staple to meals for Hawaiians. Research suggests that almost 78 percent of the diet was made up of these fiber rich carbohydrate foods.1 Carbohydrates are the perfect nutrient to meet your bodys nutritional needs. They nourish your brain and nervous system, provide energy to all of your cells when within proper caloric limits, and help keep your body fit and lean. Specifically, digestible carbohydrates provide bulk in foods, vitamins, and minerals, while 1.\\xa0Fujita R, Braun KL, Hughes CK. (2004). The traditional Hawaiian diet: a review of the literature. Pacific Health Dialogue, 11(2).',\n",
       " 'Learning Objectives By the end of this chapter, you will be able to:  Describe basic concepts in nutrition  Describe factors that affect your nutritional needs  Describe the importance of research and scientific methods to understanding nutrition What are Nutrients? The foods we eat contain nutrients. Nutrients are substances required by the body to perform its basic functions. Nutrients must be obtained from our diet, since the human body does not synthesize or produce them. Nutrients have one or more of three basic functions: they provide energy, contribute to body structure, and/or regulate chemical processes in the body. These basic functions allow us to detect and respond to environmental surroundings, move, excrete wastes, respire (breathe), grow, and reproduce. There are six classes of nutrients required for the body to function and maintain overall health. These are carbohydrates, lipids, proteins, water, vitamins, and minerals. Foods also contain non-nutrients that may be harmful (such as natural toxins common in plant foods and additives like some dyes and preservatives) or beneficial (such as antioxidants). 4 | Introduction',\n",
       " 'Water There is one other nutrient that we must have in large quantities: water. Water does not contain carbon, but is composed of two hydrogens and one oxygen per molecule of water. More than 60 percent of your total body weight is water. Without it, nothing could be transported in or out of the body, chemical reactions would not occur, organs would not be cushioned, and body temperature would fluctuate widely. On average, an adult consumes just over two liters of water per day from food and drink combined. Since water is so critical for lifes basic processes, the amount of water input and output is supremely important, a topic we will explore in detail in Chapter 4. Micronutrients Micronutrients are nutrients required by the body in lesser amounts, but are still essential for carrying out bodily functions. Micronutrients include all the essential minerals and vitamins. There are sixteen essential minerals and thirteen vitamins (See Table 1.1 Minerals and Their Major Functions and Table 1.2 Vitamins and Their Major Functions for a complete list and their major functions). In contrast to carbohydrates, lipids, and proteins, micronutrients are not sources of energy (calories), but they assist in the process as cofactors or components of enzymes (i.e., coenzymes).']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show_result= False to avoid showing the result\n",
    "\n",
    "print_top_results(\"What is the role of carbohydrates in human nutrition?\" , show_result= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3967a13",
   "metadata": {},
   "source": [
    "# 3 Generative LLM\n",
    "\n",
    "* check how much VRAM do you have available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca1fdd",
   "metadata": {},
   "source": [
    "Create cli token before download LLM \n",
    "\n",
    "Links:\n",
    "1. https://huggingface.co/docs/huggingface_hub/en/guides/cli\n",
    "2. https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0871a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU memory: 8.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = gpu_memory_bytes / (1024 ** 3)\n",
    "print(f\"Total GPU memory: {gpu_memory_gb:.2f} GB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01f4e85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 7.99560546875 | Recommended model: Gemma 2B in 4-bit precision.\n",
      "use_quantization_config set to: True\n",
      "model_id set to: google/gemma-2b-it\n"
     ]
    }
   ],
   "source": [
    "# Note: the following is Gemma focused, however, there are more and more LLMs of the 2B and 7B size appearing for local use.\n",
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention implementation set to: flash_attention_2\n",
      "Loading model google/gemma-2b-it ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|| 2/2 [00:04<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "# 1. Create a quantization \n",
    "#!pip install bitsandbytes accelerate\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit = True,\n",
    "                                         bnb_4bit_compute_dtype = torch.float16)\n",
    "\n",
    "if(is_flash_attn_2_available) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "\n",
    "else:\n",
    "    attn_implementation = \"sdpa\"   ## scaled dot-product attention \n",
    "print(f\"Attention implementation set to: {attn_implementation}\")\n",
    "\n",
    "# 2. \n",
    "# \n",
    "# model_id = \"google/gemma-2b-it\"\n",
    "model_id = model_id  \n",
    "print(  f\"Loading model {model_id} ...\")\n",
    "\n",
    "print(f\"asdfasdfasd\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path = model_id)\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path = model_id, \n",
    "                                          torch_dtype = torch.float16,\n",
    "                                          low_cpu_mem_usage=False,\n",
    "                                          #attn_implementation = attn_implementation,    ##very difficult to get flash attention work\n",
    "                                          quantization_config = quantization_config if use_quantization_config else None)\n",
    "\n",
    "if not use_quantization_config:\n",
    "    llm_model.to(\"cuda\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b946d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-torch (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
